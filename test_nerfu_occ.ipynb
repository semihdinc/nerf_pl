{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import load_ckpt, visualize_depth\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "\n",
    "import metrics\n",
    "\n",
    "from datasets import dataset_dict\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "img_wh = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your settings...\n",
    "############################\n",
    "encode_appearance = False\n",
    "N_a = 48\n",
    "encode_transient = True\n",
    "N_tau = 16\n",
    "beta_min = 0.1\n",
    "ckpt_path = 'ckpts/exp/epoch=1.ckpt'\n",
    "\n",
    "N_samples = 64\n",
    "N_importance = 64\n",
    "use_disp = False\n",
    "chunk = 1024*32\n",
    "#############################\n",
    "\n",
    "embedding_xyz = PosEmbedding(9, 10)\n",
    "embedding_dir = PosEmbedding(3, 4)\n",
    "embeddings = {'xyz': embedding_xyz, 'dir': embedding_dir}\n",
    "if encode_appearance:\n",
    "    embedding_a = torch.nn.Embedding(100, N_a).cuda()\n",
    "    load_ckpt(embedding_a, ckpt_path, model_name='embedding_a')\n",
    "    embeddings['a'] = embedding_a\n",
    "if encode_transient:\n",
    "    embedding_t = torch.nn.Embedding(100, N_tau).cuda()\n",
    "    load_ckpt(embedding_t, ckpt_path, model_name='embedding_t')\n",
    "    embeddings['t'] = embedding_t\n",
    "    \n",
    "\n",
    "nerf_coarse = NeRF('coarse').cuda()\n",
    "nerf_fine = NeRF('fine',\n",
    "                 encode_appearance=encode_appearance,\n",
    "                 in_channels_a=N_a,\n",
    "                 encode_transient=encode_transient,\n",
    "                 in_channels_t=N_tau,\n",
    "                 beta_min=beta_min).cuda()\n",
    "\n",
    "load_ckpt(nerf_coarse, ckpt_path, model_name='nerf_coarse')\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "\n",
    "models = {'coarse': nerf_coarse, 'fine': nerf_fine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def f(rays, ts):\n",
    "    \"\"\"Do batched inference on rays using chunk.\"\"\"\n",
    "    B = rays.shape[0]\n",
    "    results = defaultdict(list)\n",
    "    for i in range(0, B, chunk):\n",
    "        rendered_ray_chunks = \\\n",
    "            render_rays(models,\n",
    "                        embeddings,\n",
    "                        rays[i:i+chunk],\n",
    "                        ts[i:i+chunk],\n",
    "                        N_samples,\n",
    "                        use_disp,\n",
    "                        0,\n",
    "                        0,\n",
    "                        N_importance,\n",
    "                        chunk,\n",
    "                        dataset.white_back,\n",
    "                        test_time=True)\n",
    "\n",
    "        for k, v in rendered_ray_chunks.items():\n",
    "            results[k] += [v]\n",
    "\n",
    "    for k, v in results.items():\n",
    "        results[k] = torch.cat(v, 0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on (perturbed) train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = ['occ']\n",
    "\n",
    "dataset = dataset_dict['blender'] \\\n",
    "          ('/home/ubuntu/src/data/Street_Mesh/lego/',\n",
    "           split='test_train',\n",
    "           perturbation=perturbation,\n",
    "           img_wh=img_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample an image ...\n",
    "# 0 is unperturbed, others are perturbed\n",
    "sample = dataset[2]\n",
    "rays = sample['rays'].cuda()\n",
    "ts = sample['ts'].cuda()\n",
    "\n",
    "results = f(rays, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt = sample['rgbs'].view(img_wh[1], img_wh[0], 3)\n",
    "img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "depth_pred = results['depth_fine'].view(img_wh[1], img_wh[0])\n",
    "\n",
    "plt.subplots(figsize=(15, 8))\n",
    "plt.tight_layout()\n",
    "plt.subplot(231)\n",
    "plt.title('GT')\n",
    "plt.imshow(img_gt)\n",
    "plt.subplot(232)\n",
    "plt.title('pred')\n",
    "plt.imshow(img_pred)\n",
    "plt.subplot(233)\n",
    "plt.title('depth')\n",
    "plt.imshow(visualize_depth(depth_pred).permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "print('PSNR between GT and pred:', metrics.psnr(img_gt, img_pred).item(), '\\n')\n",
    "\n",
    "\n",
    "if encode_transient:\n",
    "    print('Decomposition--------------------------------------------' + \n",
    "          '---------------------------------------------------------' +\n",
    "          '---------------------------------------------------------' + \n",
    "          '---------------------------------------------------------')\n",
    "    img_gt_static = sample['original_rgbs'].view(img_wh[1], img_wh[0], 3)\n",
    "    valid_mask_static = sample['original_valid_mask'].view(img_wh[1], img_wh[0])\n",
    "    beta = results['beta'].view(img_wh[1], img_wh[0]).cpu().numpy()\n",
    "    img_pred_static = results['rgb_fine_static'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "    img_pred_transient = results['rgb_fine_transient'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "    depth_pred_static = results['depth_fine_static'].view(img_wh[1], img_wh[0])\n",
    "    depth_pred_transient = results['depth_fine_transient'].view(img_wh[1], img_wh[0])\n",
    "    plt.subplots(figsize=(15, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(241)\n",
    "    plt.title('original GT')\n",
    "    plt.imshow(img_gt_static)\n",
    "    plt.subplot(242)\n",
    "    plt.title('static')\n",
    "    plt.imshow(img_pred_static)\n",
    "    plt.subplot(243)\n",
    "    plt.title('transient')\n",
    "    plt.imshow(img_pred_transient)\n",
    "    plt.subplot(244)\n",
    "    plt.title('uncertainty (beta)')\n",
    "    plt.imshow(beta-beta_min, cmap='gray', vmax=beta_min/100)\n",
    "    plt.subplot(245)\n",
    "    plt.title('original valid mask')\n",
    "    plt.imshow(valid_mask_static, cmap='gray')\n",
    "    plt.subplot(246)\n",
    "    plt.title('static depth')\n",
    "    plt.imshow(visualize_depth(depth_pred_static).permute(1,2,0))\n",
    "    plt.subplot(247)\n",
    "    plt.title('transient depth')\n",
    "    plt.imshow(visualize_depth(depth_pred_transient).permute(1,2,0))\n",
    "    plt.show()\n",
    "    \n",
    "    print('PSNR between original GT and static:',\n",
    "          metrics.psnr(img_gt_static, img_pred_static).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on 63th val image (same as the image in the paper Fig 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = ['occ']\n",
    "\n",
    "dataset = dataset_dict['blender'] \\\n",
    "          ('/home/ubuntu/src/data/Street_Mesh/lego/',\n",
    "           split='val',\n",
    "           perturbation=perturbation,\n",
    "           img_wh=img_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[63]\n",
    "rays = sample['rays'].cuda()\n",
    "ts = sample['ts'].cuda()\n",
    "\n",
    "results = f(rays, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt = sample['rgbs'].view(img_wh[1], img_wh[0], 3)\n",
    "img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "depth_pred = results['depth_fine'].view(img_wh[1], img_wh[0])\n",
    "\n",
    "plt.subplots(figsize=(15, 8))\n",
    "plt.tight_layout()\n",
    "plt.subplot(231)\n",
    "plt.title('GT')\n",
    "plt.imshow(img_gt)\n",
    "plt.subplot(232)\n",
    "plt.title('pred')\n",
    "plt.imshow(img_pred)\n",
    "plt.subplot(233)\n",
    "plt.title('depth')\n",
    "plt.imshow(visualize_depth(depth_pred).permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "print('PSNR between GT and pred:', metrics.psnr(img_gt, img_pred).item(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_nsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
